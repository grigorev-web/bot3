---
title: Обзор архитектуры
description: Общая архитектура проекта и ключевые компоненты
category: architecture
tags: [архитектура, компоненты, модули, роутер, llm]
last_updated: 2024-01-01
author: Разработчик
version: 4.0.0
related_files: [src/app/app.js, src/modules/index.js, src/handlers/index.js]
---

# Обзор архитектуры

## 🏗️ Общая структура

Проект построен на модульной архитектуре с четким разделением ответственности:

```
┌─────────────────┐    ┌─────────────────┐    ┌─────────────────┐
│   Telegram Bot  │    │   Message       │    │   LLM Router    │
│   Interface     │◄──►│   Handlers      │◄──►│   (Simple)      │
└─────────────────┘    └─────────────────┘    └─────────────────┘
         │                       │                       │
         │                       │                       │
         ▼                       ▼                       ▼
┌─────────────────┐    ┌─────────────────┐    ┌─────────────────┐
│   Configuration │    │   LLM Service   │    │   External      │
│   Management    │    │   (ProxyAPI)    │    │   LLM APIs      │
└─────────────────┘    └─────────────────┘    └─────────────────┘
```

## 🔧 Ключевые компоненты

### 1. Telegram Bot Interface
- **Назначение**: Взаимодействие с Telegram Bot API
- **Файл**: `src/app/app.js`
- **Ответственность**: Получение и отправка сообщений

### 2. Message Handlers
- **Назначение**: Обработка различных типов сообщений
- **Файлы**: `src/handlers/`
- **Ответственность**: Маршрутизация сообщений к соответствующим обработчикам

### 3. LLM Router
- **Назначение**: Простая обработка сообщений через LLM
- **Файл**: `src/modules/router/router.js`
- **Ответственность**: Создание LLM сервиса, запрос к LLM и возврат ответа

### 4. LLM Service
- **Назначение**: Интеграция с внешними LLM API через ProxyAPI
- **Файл**: `src/services/llm/llmService.js`
- **Ответственность**: Взаимодействие с языковыми моделями

### 5. Configuration Management
- **Назначение**: Управление конфигурацией приложения
- **Файлы**: `src/config/`
- **Ответственность**: Загрузка настроек для разных окружений

## 🔄 Потоки данных

### Обработка входящего сообщения:

```
1. Telegram Bot API → App.js
2. App.js → Message Handler (по типу сообщения)
3. Message Handler → LLM Router (для текстовых сообщений)
4. LLM Router → LLM Service → External LLM API
5. LLM Service → Router → Handler → Ответ пользователю
```

### Обработка текстового сообщения:

```
1. TextMessageHandler получает сообщение
2. Создает SimpleRouter (ленивая загрузка)
3. Роутер создает LLM сервис (ленивая загрузка)
4. Делает запрос к LLM через ProxyAPI
5. Получает ответ и возвращает его
6. Ответ отправляется пользователю
```

## 🎯 Принципы архитектуры

### 1. Модульность
- Каждый компонент имеет четко определенную ответственность
- Модули слабо связаны между собой
- Легко добавлять новые функции

### 2. Простота
- Минимальная сложность для понимания
- Прямолинейные потоки данных
- Отсутствие избыточной абстракции

### 3. LLM-центричность
- Все текстовые сообщения обрабатываются через LLM
- Простая интеграция с внешними API
- Fallback ответы при недоступности LLM

### 4. Надежность
- Fallback ответы при ошибках
- Ленивая загрузка компонентов
- Обработка исключений на всех уровнях

## 🔌 Интерфейсы

### Router Interface
```javascript
class SimpleRouter {
  processText(text)         // Обработать текст через LLM
  isReady()                 // Проверить готовность
  getInfo()                 // Получить информацию
}
```

### Message Handler Interface
```javascript
class TextMessageHandler {
  handleTextMessage(msg)    // Обработать сообщение
  canHandle(msg)            // Проверить возможность обработки
  getModuleInfo()           // Получить информацию о модуле
}
```

## 🚀 Планы развития

### Краткосрочные (v4.1)
- Улучшение интеграции с LLM API
- Расширение конфигурации ProxyAPI
- Улучшение fallback ответов

### Среднесрочные (v4.2)
- Кэширование LLM ответов
- Метрики производительности LLM
- Система плагинов для LLM

### Долгосрочные (v5.0)
- Мультимодальные LLM (изображения, аудио)
- Персонализация LLM ответов
- Интеграция с векторными базами данных

## 📊 Метрики качества

- **Простота**: Минимальное количество зависимостей
- **Читаемость**: Понятный код без сложной логики
- **LLM интеграция**: Стабильная работа с внешними API
- **Производительность**: Быстрая обработка через LLM

## 🔍 Отладка и мониторинг

### Логирование
- Подробные логи на каждом этапе обработки
- Информация о LLM запросах и ответах
- Статистика использования LLM

### Мониторинг
- Статус готовности компонентов
- Количество обработанных сообщений
- Время отклика LLM API
- Ошибки LLM интеграции

---

*Для детальной информации о структуре проекта см. [Структура проекта](structure.md) и [Потоки данных](data-flow.md).*
