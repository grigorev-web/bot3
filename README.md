---
title: Telegram Bot - Личный ассистент с LLM
description: Телеграм бот личный ассистент с подключенным API LLM через ProxyAPI и памятью в базе данных
category: main
tags: [telegram, bot, nodejs, llm, ai, ассистент, база данных, память, proxyapi]
last_updated: 2024-01-01
author: Разработчик
version: 1.0.0
related_files: [src/app/app.js, src/handlers/index.js, src/modules/index.js]
---

# Telegram Bot с LLM Роутером

Простой и эффективный Telegram бот с модульной архитектурой и LLM роутером для обработки сообщений через языковые модели.

## 🚀 Особенности

- **LLM интеграция** - Обработка сообщений через языковые модели
- **Простая архитектура** - Минимальная сложность для понимания
- **Модульный дизайн** - Легко добавлять новые функции
- **LLM роутер** - Прямая обработка через LLM без сложной логики
- **Ленивая загрузка** - Компоненты загружаются по требованию
- **Fallback система** - Работает даже при недоступности LLM
- **ProxyAPI поддержка** - Интеграция с различными LLM провайдерами

## 🏗️ Архитектура

```
┌─────────────────┐    ┌─────────────────┐    ┌─────────────────┐
│   Telegram Bot  │    │   Message       │    │   LLM Router    │
│   Interface     │◄──►│   Handlers      │◄──►│   (Simple)      │
└─────────────────┘    └─────────────────┘    └─────────────────┘
         │                       │                       │
         │                       │                       │
         ▼                       ▼                       ▼
┌─────────────────┐    ┌─────────────────┐    ┌─────────────────┐
│   Configuration │    │   LLM Service   │    │   External      │
│   Management    │    │   (ProxyAPI)    │    │   LLM APIs      │
└─────────────────┘    └─────────────────┘    └─────────────────┘
```

## 📁 Структура проекта

```
src/
├── app/           # Основное приложение
├── config/        # Конфигурационные файлы
├── handlers/      # Обработчики сообщений
├── modules/       # Модули (LLM роутер, классификатор)
└── services/      # Сервисы (LLM сервис)
```

## 🔧 Установка

1. **Клонируйте репозиторий**
```bash
git clone <repository-url>
cd bot3
```

2. **Установите зависимости**
```bash
npm install
```

3. **Настройте переменные окружения**
```bash
cp env.example .env
# Отредактируйте .env файл
```

4. **Запустите бота**
```bash
npm start
```

## 📖 Использование

### Базовые команды
- `/start` - Начать работу с ботом
- `/help` - Получить справку

### Обработка сообщений
Бот автоматически обрабатывает все текстовые сообщения через LLM:

- **Любые текстовые сообщения** отправляются в LLM
- **LLM анализирует** контекст и генерирует ответ
- **Fallback ответы** при недоступности LLM

## 🎯 Принципы дизайна

### 1. Простота
- Минимальная сложность для понимания
- Прямолинейные потоки данных
- Отсутствие избыточной абстракции

### 2. LLM-центричность
- Все текстовые сообщения обрабатываются через LLM
- Простая интеграция с внешними API
- Fallback ответы при недоступности LLM

### 3. Модульность
- Каждый компонент имеет четко определенную ответственность
- Модули слабо связаны между собой
- Легко добавлять новые функции

### 4. Надежность
- Fallback ответы при ошибках
- Ленивая загрузка компонентов
- Обработка исключений на всех уровнях

## 🔌 API и интеграции

### Текущие возможности
- **Telegram Bot API** - Основное взаимодействие
- **LLM Router** - Обработка сообщений через языковые модели
- **ProxyAPI интеграция** - Доступ к различным LLM провайдерам

### Поддерживаемые LLM провайдеры
- **OpenAI** - GPT-4, GPT-3.5-turbo
- **Anthropic** - Claude Sonnet, Claude Haiku
- **Gemini** - Gemini Pro, Gemini Flash
- **DeepSeek** - DeepSeek Chat

### ProxyAPI преимущества
- Единый API для всех провайдеров
- Европейские серверы для стабильности
- Автоматическая маршрутизация по моделям
- Управление через единый интерфейс

## 🚀 Разработка

### Создание нового обработчика

```javascript
class CustomHandler {
  canHandle(message) {
    return message.type === 'custom';
  }
  
  async handle(message) {
    // Логика обработки
    return 'Ответ';
  }
}
```

### Расширение LLM функциональности

```javascript
// В LLM сервисе можно добавить новые модели
const newModel = {
  name: 'custom-model',
  provider: 'openai',
  model: 'gpt-4-turbo'
};
```

## 📊 Мониторинг

### Логирование
- Подробные логи на каждом этапе обработки
- Информация о LLM запросах и ответах
- Статистика использования LLM

### Метрики
- Статус готовности компонентов
- Количество обработанных сообщений
- Время отклика LLM API
- Ошибки LLM интеграции

## 🔒 Безопасность

- Валидация входящих данных
- Санитизация пользовательского ввода перед отправкой в LLM
- Безопасное хранение API ключей
- Логирование всех LLM взаимодействий
- Обработка исключений

## 📚 Документация

Подробная документация находится в папке `docs/`:

- [Архитектура](docs/architecture/overview.md)
- [Структура модулей](docs/architecture/modules-structure.md)
- [Руководства](docs/guides/)
- [API документация](docs/api/)

## 🤝 Вклад в проект

1. Форкните репозиторий
2. Создайте ветку для новой функции
3. Внесите изменения
4. Создайте Pull Request

## 📄 Лицензия

MIT License - см. файл [LICENSE](LICENSE) для деталей.

## 🆘 Поддержка

- **Issues**: [GitHub Issues](https://github.com/your-repo/issues)
- **Discussions**: [GitHub Discussions](https://github.com/your-repo/discussions)
- **Документация**: [docs/](docs/)

---

**Версия**: 4.0.0  
**Последнее обновление**: 2024-01-01  
**Статус**: Активная разработка
